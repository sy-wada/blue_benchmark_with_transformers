{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6Qe7K2cJxmC",
        "outputId": "f7c13203-d220-48ed-b45c-7b67b431b2b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (10.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers numpy nltk pandas pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "Zf9f1BHYJxmD",
        "outputId": "b71da39c-2ff7-420e-cb9c-2159cb40f394"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "from utils import (\n",
        "    create_balanced_vocabulary,\n",
        "    sharding,\n",
        "    create_training_instances\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5RT63LHIJxmE"
      },
      "outputs": [],
      "source": [
        "tokenizer_path = './balanced_vocabulary/'\n",
        "small_path = Path('./data/one_article_per_line/PubMedAbstract_1MB.txt')\n",
        "large_path = Path('./data/one_article_per_line/Wiki_EN_10MB.txt')\n",
        "sharded_size = 100000   # 100KB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj_oTdzlJxmE"
      },
      "source": [
        "## Create Balanced Vocabulary from two corpora."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7UY_o7MvJxmE",
        "outputId": "80e44d0f-3dcf-4b03-c296-dd4908e69285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "create_balanced_vocabulary(\n",
        "        small_path=small_path,\n",
        "        large_path=large_path,\n",
        "        output_dir=tokenizer_path,\n",
        "        vocab_size=8000\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AOSiKmXFJxmF",
        "outputId": "5b8d71d9-7b3b-4c94-e0f1-728b5eb8a87c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./balanced_vocabulary/tokenizer_config.json',\n",
              " './balanced_vocabulary/special_tokens_map.json',\n",
              " './balanced_vocabulary/vocab.txt',\n",
              " './balanced_vocabulary/added_tokens.json')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = BertTokenizer(vocab_file=Path(tokenizer_path) / 'vocab.txt',\n",
        "                          do_lower_case=True, do_basic_tokenize=True)\n",
        "tokenizer.save_pretrained(tokenizer_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH-7bGXPJxmF"
      },
      "source": [
        "## Text Sharding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pX9lqK9-JxmF",
        "outputId": "20edef2d-67eb-4cf6-dbaf-0a9cadffd25e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start: Init Output Files\n",
            "End: Init Output Files\n",
            "Start: Loading Articles\n",
            "input file: data/one_article_per_line/PubMedAbstract_1MB.txt\n",
            "End: Loading Articles: There are 725 articles.\n",
            "Start: Sentence Segmentation\n",
            "Segmenting article 0\n",
            "End: Sentence Segmentation\n",
            "Start: Distribute Articles Over Shards\n",
            "Distributing data over shards: 710 articles remaining.\n",
            "Distributing data over shards: 705 articles remaining.\n",
            "Distributing data over shards: 698 articles remaining.\n",
            "Distributing data over shards: 693 articles remaining.\n",
            "Distributing data over shards: 687 articles remaining.\n",
            "Distributing data over shards: 682 articles remaining.\n",
            "Distributing data over shards: 676 articles remaining.\n",
            "Distributing data over shards: 669 articles remaining.\n",
            "Distributing data over shards: 662 articles remaining.\n",
            "Distributing data over shards: 656 articles remaining.\n",
            "Distributing data over shards: 651 articles remaining.\n",
            "Distributing data over shards: 646 articles remaining.\n",
            "Distributing data over shards: 641 articles remaining.\n",
            "Distributing data over shards: 636 articles remaining.\n",
            "Distributing data over shards: 631 articles remaining.\n",
            "Distributing data over shards: 626 articles remaining.\n",
            "Distributing data over shards: 621 articles remaining.\n",
            "Distributing data over shards: 616 articles remaining.\n",
            "Distributing data over shards: 609 articles remaining.\n",
            "Distributing data over shards: 603 articles remaining.\n",
            "Distributing data over shards: 596 articles remaining.\n",
            "Distributing data over shards: 589 articles remaining.\n",
            "Distributing data over shards: 583 articles remaining.\n",
            "Distributing data over shards: 576 articles remaining.\n",
            "Distributing data over shards: 569 articles remaining.\n",
            "Distributing data over shards: 563 articles remaining.\n",
            "Distributing data over shards: 556 articles remaining.\n",
            "Distributing data over shards: 549 articles remaining.\n",
            "Distributing data over shards: 543 articles remaining.\n",
            "Distributing data over shards: 536 articles remaining.\n",
            "Distributing data over shards: 529 articles remaining.\n",
            "Distributing data over shards: 523 articles remaining.\n",
            "Distributing data over shards: 516 articles remaining.\n",
            "Distributing data over shards: 509 articles remaining.\n",
            "Distributing data over shards: 503 articles remaining.\n",
            "Distributing data over shards: 496 articles remaining.\n",
            "Distributing data over shards: 489 articles remaining.\n",
            "Distributing data over shards: 483 articles remaining.\n",
            "Distributing data over shards: 476 articles remaining.\n",
            "Distributing data over shards: 471 articles remaining.\n",
            "Distributing data over shards: 466 articles remaining.\n",
            "Distributing data over shards: 461 articles remaining.\n",
            "Distributing data over shards: 456 articles remaining.\n",
            "Distributing data over shards: 451 articles remaining.\n",
            "Distributing data over shards: 446 articles remaining.\n",
            "Distributing data over shards: 441 articles remaining.\n",
            "Distributing data over shards: 436 articles remaining.\n",
            "Distributing data over shards: 431 articles remaining.\n",
            "Distributing data over shards: 426 articles remaining.\n",
            "Distributing data over shards: 421 articles remaining.\n",
            "Distributing data over shards: 416 articles remaining.\n",
            "Distributing data over shards: 411 articles remaining.\n",
            "Distributing data over shards: 406 articles remaining.\n",
            "Distributing data over shards: 401 articles remaining.\n",
            "Distributing data over shards: 396 articles remaining.\n",
            "Distributing data over shards: 391 articles remaining.\n",
            "Distributing data over shards: 386 articles remaining.\n",
            "Distributing data over shards: 376 articles remaining.\n",
            "Distributing data over shards: 366 articles remaining.\n",
            "Distributing data over shards: 356 articles remaining.\n",
            "Distributing data over shards: 346 articles remaining.\n",
            "Distributing data over shards: 336 articles remaining.\n",
            "Distributing data over shards: 326 articles remaining.\n",
            "Distributing data over shards: 316 articles remaining.\n",
            "Distributing data over shards: 306 articles remaining.\n",
            "Distributing data over shards: 296 articles remaining.\n",
            "Distributing data over shards: 286 articles remaining.\n",
            "Distributing data over shards: 276 articles remaining.\n",
            "Distributing data over shards: 266 articles remaining.\n",
            "Distributing data over shards: 256 articles remaining.\n",
            "Distributing data over shards: 246 articles remaining.\n",
            "Distributing data over shards: 236 articles remaining.\n",
            "Distributing data over shards: 226 articles remaining.\n",
            "Distributing data over shards: 216 articles remaining.\n",
            "Distributing data over shards: 206 articles remaining.\n",
            "Distributing data over shards: 196 articles remaining.\n",
            "Distributing data over shards: 186 articles remaining.\n",
            "Distributing data over shards: 176 articles remaining.\n",
            "Distributing data over shards: 166 articles remaining.\n",
            "Distributing data over shards: 156 articles remaining.\n",
            "Distributing data over shards: 146 articles remaining.\n",
            "Distributing data over shards: 136 articles remaining.\n",
            "Distributing data over shards: 127 articles remaining.\n",
            "Distributing data over shards: 122 articles remaining.\n",
            "Distributing data over shards: 117 articles remaining.\n",
            "Distributing data over shards: 112 articles remaining.\n",
            "Distributing data over shards: 107 articles remaining.\n",
            "Distributing data over shards: 102 articles remaining.\n",
            "Distributing data over shards: 97 articles remaining.\n",
            "Distributing data over shards: 92 articles remaining.\n",
            "Distributing data over shards: 87 articles remaining.\n",
            "Distributing data over shards: 82 articles remaining.\n",
            "Distributing data over shards: 77 articles remaining.\n",
            "Distributing data over shards: 72 articles remaining.\n",
            "Distributing data over shards: 67 articles remaining.\n",
            "Distributing data over shards: 62 articles remaining.\n",
            "Distributing data over shards: 57 articles remaining.\n",
            "Distributing data over shards: 50 articles remaining.\n",
            "Distributing data over shards: 43 articles remaining.\n",
            "Distributing data over shards: 36 articles remaining.\n",
            "Distributing data over shards: 30 articles remaining.\n",
            "Distributing data over shards: 23 articles remaining.\n",
            "Distributing data over shards: 17 articles remaining.\n",
            "Distributing data over shards: 7 articles remaining.\n",
            "Distributing data over shards: 1 articles remaining.\n",
            "Distributing data over shards: 1 articles remaining.\n",
            "Distributing data over shards: 1 articles remaining.\n",
            "Distributing data over shards: 1 articles remaining.\n",
            "Distributing data over shards: 0 articles remaining.\n",
            "Training shard: 635\n",
            "Training shard: 636\n",
            "Training shard: 635\n",
            "Training shard: 635\n",
            "Training shard: 633\n",
            "Training shard: 633\n",
            "Training shard: 633\n",
            "Training shard: 633\n",
            "Training shard: 634\n",
            "Training shard: 633\n",
            "End: Distribute Articles Over Shards\n",
            "Start: Write Shards to Disk\n",
            "End: Write Shards to Disk\n"
          ]
        }
      ],
      "source": [
        "# PubMed Abstract\n",
        "sharding(\n",
        "        input_files=small_path,\n",
        "        output_file_prefix='PubMed1M',\n",
        "        output_dir='./data/sharded_text/',\n",
        "        n_shards=round(small_path.stat().st_size / sharded_size)  # 10 files\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YhqHqZVsJxmF",
        "outputId": "09517672-74bc-4240-9067-c0503c0f8451"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start: Init Output Files\n",
            "End: Init Output Files\n",
            "Start: Loading Articles\n",
            "input file: data/one_article_per_line/Wiki_EN_10MB.txt\n",
            "End: Loading Articles: There are 2196 articles.\n",
            "Start: Sentence Segmentation\n",
            "Segmenting article 0\n",
            "End: Sentence Segmentation\n",
            "Start: Distribute Articles Over Shards\n",
            "Warning: A single article contains more than the nominal number of sentences per training shard.\n",
            "Distributing data over shards: 2046 articles remaining.\n",
            "Distributing data over shards: 1996 articles remaining.\n",
            "Distributing data over shards: 1945 articles remaining.\n",
            "Distributing data over shards: 1893 articles remaining.\n",
            "Distributing data over shards: 1842 articles remaining.\n",
            "Distributing data over shards: 1791 articles remaining.\n",
            "Distributing data over shards: 1741 articles remaining.\n",
            "Distributing data over shards: 1688 articles remaining.\n",
            "Distributing data over shards: 1635 articles remaining.\n",
            "Distributing data over shards: 1584 articles remaining.\n",
            "Distributing data over shards: 1534 articles remaining.\n",
            "Distributing data over shards: 1484 articles remaining.\n",
            "Distributing data over shards: 1428 articles remaining.\n",
            "Distributing data over shards: 1377 articles remaining.\n",
            "Distributing data over shards: 1322 articles remaining.\n",
            "Distributing data over shards: 1270 articles remaining.\n",
            "Distributing data over shards: 1218 articles remaining.\n",
            "Distributing data over shards: 1168 articles remaining.\n",
            "Distributing data over shards: 1117 articles remaining.\n",
            "Distributing data over shards: 1066 articles remaining.\n",
            "Distributing data over shards: 1014 articles remaining.\n",
            "Distributing data over shards: 961 articles remaining.\n",
            "Distributing data over shards: 911 articles remaining.\n",
            "Distributing data over shards: 861 articles remaining.\n",
            "Distributing data over shards: 804 articles remaining.\n",
            "Distributing data over shards: 753 articles remaining.\n",
            "Distributing data over shards: 700 articles remaining.\n",
            "Distributing data over shards: 650 articles remaining.\n",
            "Distributing data over shards: 597 articles remaining.\n",
            "Distributing data over shards: 547 articles remaining.\n",
            "Distributing data over shards: 494 articles remaining.\n",
            "Distributing data over shards: 444 articles remaining.\n",
            "Distributing data over shards: 392 articles remaining.\n",
            "Distributing data over shards: 341 articles remaining.\n",
            "Distributing data over shards: 290 articles remaining.\n",
            "Distributing data over shards: 240 articles remaining.\n",
            "Distributing data over shards: 186 articles remaining.\n",
            "Distributing data over shards: 133 articles remaining.\n",
            "Distributing data over shards: 80 articles remaining.\n",
            "Distributing data over shards: 20 articles remaining.\n",
            "Distributing data over shards: 0 articles remaining.\n",
            "Training shard: 989\n",
            "Training shard: 760\n",
            "Training shard: 766\n",
            "Training shard: 764\n",
            "Training shard: 764\n",
            "Training shard: 763\n",
            "Training shard: 764\n",
            "Training shard: 764\n",
            "Training shard: 764\n",
            "Training shard: 764\n",
            "Training shard: 764\n",
            "Training shard: 763\n",
            "Training shard: 764\n",
            "Training shard: 763\n",
            "Training shard: 762\n",
            "Training shard: 763\n",
            "Training shard: 763\n",
            "Training shard: 763\n",
            "Training shard: 763\n",
            "Training shard: 762\n",
            "Training shard: 762\n",
            "Training shard: 762\n",
            "Training shard: 761\n",
            "Training shard: 757\n",
            "Training shard: 757\n",
            "Training shard: 757\n",
            "Training shard: 757\n",
            "Training shard: 756\n",
            "Training shard: 757\n",
            "Training shard: 756\n",
            "Training shard: 757\n",
            "Training shard: 763\n",
            "Training shard: 756\n",
            "Training shard: 756\n",
            "Training shard: 761\n",
            "Training shard: 761\n",
            "Training shard: 756\n",
            "Training shard: 761\n",
            "Training shard: 761\n",
            "Training shard: 759\n",
            "Training shard: 757\n",
            "Training shard: 756\n",
            "Training shard: 763\n",
            "Training shard: 763\n",
            "Training shard: 763\n",
            "Training shard: 763\n",
            "Training shard: 763\n",
            "Training shard: 763\n",
            "Training shard: 763\n",
            "Training shard: 763\n",
            "Training shard: 759\n",
            "Training shard: 757\n",
            "Training shard: 756\n",
            "Training shard: 763\n",
            "Training shard: 763\n",
            "Training shard: 763\n",
            "Training shard: 763\n",
            "Training shard: 763\n",
            "Training shard: 763\n",
            "Training shard: 763\n",
            "Training shard: 763\n",
            "Training shard: 762\n",
            "Training shard: 763\n",
            "Training shard: 762\n",
            "Training shard: 762\n",
            "Training shard: 760\n",
            "Training shard: 761\n",
            "Training shard: 762\n",
            "Training shard: 760\n",
            "Training shard: 760\n",
            "Training shard: 760\n",
            "Training shard: 760\n",
            "Training shard: 760\n",
            "Training shard: 760\n",
            "Training shard: 760\n",
            "Training shard: 760\n",
            "Training shard: 760\n",
            "Training shard: 760\n",
            "Training shard: 760\n",
            "Training shard: 760\n",
            "Training shard: 759\n",
            "Training shard: 759\n",
            "Training shard: 757\n",
            "Training shard: 757\n",
            "Training shard: 759\n",
            "Training shard: 759\n",
            "Training shard: 757\n",
            "Training shard: 757\n",
            "Training shard: 756\n",
            "Training shard: 757\n",
            "Training shard: 757\n",
            "Training shard: 757\n",
            "Training shard: 756\n",
            "Training shard: 756\n",
            "Training shard: 756\n",
            "Training shard: 756\n",
            "Training shard: 756\n",
            "Training shard: 756\n",
            "Training shard: 762\n",
            "Training shard: 761\n",
            "End: Distribute Articles Over Shards\n",
            "Start: Write Shards to Disk\n",
            "End: Write Shards to Disk\n"
          ]
        }
      ],
      "source": [
        "# English Wiki corpus\n",
        "sharding(\n",
        "        input_files=large_path,\n",
        "        output_file_prefix='Wiki10M',\n",
        "        output_dir='./data/sharded_text/',\n",
        "        n_shards=round(large_path.stat().st_size / sharded_size)  # 100 files\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EOwBKNhJxmF"
      },
      "source": [
        "## (Demo) Create Instances for BERT Pretraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_GO1uzpTJxmF",
        "outputId": "8667ffc2-dd3b-408d-d6ea-f4d4d9ad06da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of instances: 867. Save to data/pretraining_instances/sample_32.txt\n",
            "Number of instances: 841. Save to data/pretraining_instances/sample_18.txt\n",
            "Number of instances: 834. Save to data/pretraining_instances/sample_30.txt\n",
            "Number of instances: 845. Save to data/pretraining_instances/sample_26.txt\n",
            "Number of instances: 852. Save to data/pretraining_instances/sample_37.txt\n",
            "Number of instances: 839. Save to data/pretraining_instances/sample_42.txt\n",
            "Number of instances: 847. Save to data/pretraining_instances/sample_25.txt\n",
            "Number of instances: 850. Save to data/pretraining_instances/sample_35.txt\n",
            "Number of instances: 840. Save to data/pretraining_instances/sample_22.txt\n",
            "Number of instances: 845. Save to data/pretraining_instances/sample_23.txt\n",
            "Number of instances: 855. Save to data/pretraining_instances/sample_49.txt\n",
            "Number of instances: 840. Save to data/pretraining_instances/sample_29.txt\n",
            "Number of instances: 860. Save to data/pretraining_instances/sample_16.txt\n",
            "Number of instances: 819. Save to data/pretraining_instances/sample_15.txt\n",
            "Number of instances: 848. Save to data/pretraining_instances/sample_45.txt\n",
            "Number of instances: 846. Save to data/pretraining_instances/sample_11.txt\n",
            "Number of instances: 850. Save to data/pretraining_instances/sample_33.txt\n",
            "Number of instances: 862. Save to data/pretraining_instances/sample_40.txt\n",
            "Number of instances: 840. Save to data/pretraining_instances/sample_9.txt\n",
            "Number of instances: 829. Save to data/pretraining_instances/sample_24.txt\n",
            "Number of instances: 853. Save to data/pretraining_instances/sample_2.txt\n",
            "Number of instances: 855. Save to data/pretraining_instances/sample_19.txt\n",
            "Number of instances: 846. Save to data/pretraining_instances/sample_10.txt\n",
            "Number of instances: 848. Save to data/pretraining_instances/sample_27.txt\n",
            "Number of instances: 835. Save to data/pretraining_instances/sample_41.txt\n",
            "Number of instances: 853. Save to data/pretraining_instances/sample_28.txt\n",
            "Number of instances: 838. Save to data/pretraining_instances/sample_38.txt\n",
            "Number of instances: 854. Save to data/pretraining_instances/sample_5.txt\n",
            "Number of instances: 824. Save to data/pretraining_instances/sample_47.txt\n",
            "Number of instances: 861. Save to data/pretraining_instances/sample_17.txt\n",
            "Number of instances: 841. Save to data/pretraining_instances/sample_8.txt\n",
            "Number of instances: 842. Save to data/pretraining_instances/sample_43.txt\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of instances: 884. Save to data/pretraining_instances/sample_0.txt\n",
            "Number of instances: 867. Save to data/pretraining_instances/sample_39.txt\n",
            "Number of instances: 838. Save to data/pretraining_instances/sample_1.txt\n",
            "Number of instances: 861. Save to data/pretraining_instances/sample_6.txt\n",
            "Number of instances: 856. Save to data/pretraining_instances/sample_20.txt\n",
            "Number of instances: 846. Save to data/pretraining_instances/sample_34.txt\n",
            "Number of instances: 857. Save to data/pretraining_instances/sample_46.txt\n",
            "Number of instances: 861. Save to data/pretraining_instances/sample_3.txt\n",
            "Number of instances: 841. Save to data/pretraining_instances/sample_4.txt\n",
            "Number of instances: 842. Save to data/pretraining_instances/sample_44.txt\n",
            "Number of instances: 891. Save to data/pretraining_instances/sample_48.txt\n",
            "Number of instances: 841. Save to data/pretraining_instances/sample_13.txt\n",
            "Number of instances: 826. Save to data/pretraining_instances/sample_36.txtNumber of instances: 873. Save to data/pretraining_instances/sample_7.txt\n",
            "\n",
            "Number of instances: 867. Save to data/pretraining_instances/sample_31.txt\n",
            "Number of instances: 863. Save to data/pretraining_instances/sample_21.txt\n",
            "Number of instances: 845. Save to data/pretraining_instances/sample_12.txt\n",
            "Number of instances: 832. Save to data/pretraining_instances/sample_14.txt\n"
          ]
        }
      ],
      "source": [
        "composition = create_training_instances(\n",
        "        small_corpus_dir='./data/sharded_text/PubMedAbstract_1MB/',\n",
        "        large_corpus_dir='./data/sharded_text/Wiki_EN_10MB/',\n",
        "        output_dir='./data/pretraining_instances',\n",
        "        tokenizer_path=tokenizer_path,\n",
        "        filename_prefix='sample',\n",
        "        n_convoys=5,\n",
        "        n_escorts=5,\n",
        "        n_training_files=50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bccew_dFJxmG"
      },
      "outputs": [],
      "source": [
        "pprint(composition)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env_spt",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
